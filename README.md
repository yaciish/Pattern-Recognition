# Pattern-Recognition

Learning folder:
- Part 1:
    * Generate Gaussian random vectors using uniform random variables.
    * Diagonalize the distributions
    * Generating 200 points of each distribution before diagonalization and plotting them
    * Generating 200 points of each distribution after diagonalization and plotting them

- Part 2:
    * Generate 200 points of each distribution before diagonalization and plot them.
    * Compute the optimal Bayes discriminant function for the points
    * Generate 200 new points for each class for testing.
    * plot training points after diagonalization
    * compute the optimal Bayes discriminant function for the testing points
 
- Part 3:
    * Generate 200 training points before diagonalization and plot.
    * estimate the parameters of each distribution using maximum likelihood (ML) and Bayesian methodology.
    * estimate each univariate distribution using a Parzen Window approach.
    * compute the optimal Bayes discriminant function for ML, Bayes, and Parzen schemes.
    * Generate 200 new points for each class for testing using a ten-fold cross validation.


Final Project:
- This project aims to compare the performance (accuracy measure) of three different classifiers, namely
Quadratic, K-Nearest Neighbors, and Ho-Kashyap, in a binary classification problem. According to the
results, Quadratic and Ho-Kashyap algorithms work the best in favor of both classes. In the following
sections, we will introduce the dataset, methods to obtain mean and covariance for each class, each of
the classifiers, a brief explanation of the classifiers, the results, and a discussion are provided
